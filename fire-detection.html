<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Experiment 1: Fire Detection | DARUKA VLab</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

<header class="top-bar">
  <a href="experiments.html" class="back-link">‚Üê Experiments</a>
  <h2>Experiment 1 ‚Äî Fire Detection</h2>
  <nav class="top-bar-nav">
    <a href="navigation.html">Experiment 2 ‚Üí</a>
  </nav>
</header>

<div class="fd-layout">

  <div class="fd-main">
    <div class="fd-video-wrap" id="videoWrap">
      <video id="camVideo" autoplay playsinline muted></video>
      <canvas id="overlayCanvas"></canvas>
      
      <div class="fd-placeholder" id="camPlaceholder">
        <span class="fd-cam-icon">üì∑</span>
        <p>Camera feed will appear here</p>
        <small>Click <strong>Start Camera</strong> to begin detection</small>
      </div>
      
      <div class="fd-live-badge" id="liveBadge">‚óè LIVE</div>
      <div class="fd-yolo-tag" id="yoloTag">System Ready</div>
    </div>
  </div>

  <aside class="fd-sidebar">

    <div class="control-group">
      <h3>Detection Logic</h3>
      <div class="mode-toggle">
        <button class="mode-btn active" id="modeOnnx" onclick="setMode('onnx')">ONNX (AI)</button>
        <button class="mode-btn" id="modeHsv" onclick="setMode('hsv')">HSV (Rules)</button>
      </div>
    </div>

    <div class="control-group">
      <h3>Camera Controls</h3>
      <div class="fd-btn-row">
        <button class="btn btn-start-cam" id="btnStart" onclick="startCamera()">‚ñ∂ Start Camera</button>
        <button class="btn btn-stop-cam" id="btnStop" onclick="stopCamera()" disabled>‚ñ† Stop</button>
      </div>
    </div>

    <div class="control-group">
      <h3>Parameters</h3>
      <div class="param-row">
        <label>Confidence</label>
        <input type="range" id="thresholdSlider" min="10" max="95" value="40" oninput="updateThreshold(this.value)">
        <span class="param-val" id="thresholdVal">0.40</span>
      </div>
      <div class="param-row">
        <label>Throttle</label>
        <input type="range" id="pollSlider" min="0" max="1000" value="100" step="50" oninput="updatePoll(this.value)">
        <span class="param-val" id="pollVal">100ms</span>
      </div>
    </div>

    <div class="control-group">
      <h3>Live Detection Stats</h3>
      <div class="fd-stats">
        <div class="fd-stat"><div class="fs-label">Status</div><div class="fs-value" id="statStatus">IDLE</div></div>
        <div class="fd-stat fire-on"><div class="fs-label">Fire</div><div class="fs-value" id="statFire">‚Äî</div></div>
        <div class="fd-stat"><div class="fs-label">Confidence</div><div class="fs-value" id="statConf">‚Äî</div></div>
        <div class="fd-stat"><div class="fs-label">Detections</div><div class="fs-value" id="statCount">0</div></div>
        <div class="fd-stat"><div class="fs-label">Mode</div><div class="fs-value" id="statMode">ONNX</div></div>
        <div class="fd-stat"><div class="fs-label">Latency</div><div class="fs-value" id="statLatency">‚Äî</div></div>
      </div>
    </div>

    <div class="control-group">
      <h3>Glass-Box AI</h3>
      <div class="fd-glass-box">
        <h4>System Internals</h4>
        <p id="glassBoxText">System is idle. Select a mode and start the camera to visualize the decision-making process.</p>
      </div>
    </div>

    <div class="control-group fill-height">
      <h3>Detection Log</h3>
      <div class="console-box" id="logBox">
        <p class="sys">[SYS] System Ready.</p>
      </div>
    </div>

  </aside>
</div>

<script>
/* --- CONFIGURATION --- */
const ONNX_MODEL_PATH = './best.onnx'; // Relative path
let threshold = 0.40;
let pollRate = 100; // ms between frames
let activeMode = 'onnx'; // 'onnx' or 'hsv'

/* --- STATE --- */
let camStream = null;
let detectionLoopId = null;
let ortSession = null;
let isModelLoading = false;
let lastProcessTime = 0;

/* --- ELEMENTS --- */
const video = document.getElementById('camVideo');
const canvas = document.getElementById('overlayCanvas');
const ctx = canvas.getContext('2d', { willReadFrequently: true });

// --- Log utility ---
function log(msg, cls = '') {
  const box = document.getElementById('logBox');
  const p = document.createElement('p');
  if (cls) p.className = cls;
  p.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
  box.prepend(p);
}

// --- Mode Selection ---
function setMode(mode) {
  activeMode = mode;
  document.getElementById('modeOnnx').className = mode === 'onnx' ? 'mode-btn active' : 'mode-btn';
  document.getElementById('modeHsv').className = mode === 'hsv' ? 'mode-btn active' : 'mode-btn';
  
  document.getElementById('statMode').textContent = mode.toUpperCase();
  document.getElementById('yoloTag').textContent = mode === 'onnx' ? 'YOLOv8 ¬∑ fire-detection' : 'HSV ¬∑ Color Thresholding';
  
  if (mode === 'onnx') {
    document.getElementById('glassBoxText').textContent = "Switched to Deep Learning. Using Convolutional Neural Network (YOLOv8) to identify fire patterns based on learned features.";
    if (!ortSession && !isModelLoading) initONNX();
  } else {
    document.getElementById('glassBoxText').textContent = "Switched to Computer Vision (HSV). Algorithm scans pixels for specific High-Saturation, High-Value Orange/Red hues.";
  }
  log(`Mode switched to ${mode.toUpperCase()}`, 'sys');
}

// --- UI Updates ---
function updateThreshold(val) {
  threshold = val / 100;
  document.getElementById('thresholdVal').textContent = threshold.toFixed(2);
}

function updatePoll(val) {
  pollRate = parseInt(val);
  document.getElementById('pollVal').textContent = pollRate + 'ms';
}

// --- ONNX Initialization ---
// --- ONNX Initialization ---
async function initONNX() {
  if (ortSession || isModelLoading) return;
  isModelLoading = true;
  log('Loading ONNX model...', 'sys');
  document.getElementById('yoloTag').textContent = "Loading ONNX...";
  
  // DISABLE ONNX WARNINGS (Fix for "Unknown CPU vendor" logs)
  ort.env.logLevel = 'error'; // Global log level
  
  try {
    // 1. Verify file exists
    const response = await fetch(ONNX_MODEL_PATH, { method: 'HEAD' });
    if (!response.ok && response.status === 404) {
       throw new Error(`File not found: ${ONNX_MODEL_PATH}`);
    }

    // 2. Create Session with suppressed logs
    ortSession = await ort.InferenceSession.create(ONNX_MODEL_PATH, {
      executionProviders: ['wasm'], 
      graphOptimizationLevel: 'all',
      executionMode: 'sequential', 
      intraOpNumThreads: 1,
      logSeverityLevel: 3  // 0:Verbose, 1:Info, 2:Warning, 3:Error, 4:Fatal
    });

    log('ONNX Model loaded successfully.', 'sys');
    document.getElementById('yoloTag').textContent = "YOLOv8 ¬∑ Ready";
  } catch (e) {
    console.error(e);
    log(`ERROR: Could not load model. ${e.message}`, 'err');
    log(`Verify file exists at: public/best.onnx`, 'warn');
    document.getElementById('yoloTag').textContent = "Model Error";
    document.getElementById('glassBoxText').textContent = "‚ö†Ô∏è Error: Model file not found or blocked. Switched to HSV mode automatically.";
    setMode('hsv');
  } finally {
    isModelLoading = false;
  }
}

// --- Camera Logic ---
async function startCamera() {
  if (!ortSession && activeMode === 'onnx') await initONNX();

  try {
    const constraints = { 
      video: { 
        facingMode: 'environment', 
        width: { ideal: 640 }, 
        height: { ideal: 640 } 
      } 
    };
    camStream = await navigator.mediaDevices.getUserMedia(constraints);
    
    video.srcObject = camStream;
    // Wait for metadata to set canvas size
    video.onloadedmetadata = () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      video.play();
    };

    // UI Updates
    document.getElementById('camPlaceholder').style.display = 'none';
    document.getElementById('liveBadge').style.display = 'block';
    document.getElementById('yoloTag').style.display = 'block';
    document.getElementById('btnStart').disabled = true;
    document.getElementById('btnStop').disabled = false;
    document.getElementById('statStatus').textContent = 'ACTIVE';
    
    
    log('Camera active. Starting pipeline.', 'sys');
    requestAnimationFrame(processFrame);

  } catch (err) {
    console.error(err);
    log('Camera access denied.', 'err');
    document.getElementById('statStatus').textContent = 'ERROR';
  }
}

function stopCamera() {
  if (camStream) {
    camStream.getTracks().forEach(t => t.stop());
    camStream = null;
  }
  cancelAnimationFrame(detectionLoopId);
  video.srcObject = null;
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  
  // Reset UI
  document.getElementById('camPlaceholder').style.display = 'flex';
  document.getElementById('liveBadge').style.display = 'none';
  document.getElementById('yoloTag').style.display = 'none';
  document.getElementById('btnStart').disabled = false;
  document.getElementById('btnStop').disabled = true;
  document.getElementById('statStatus').textContent = 'IDLE';
  
  document.getElementById('statFire').textContent = '‚Äî';
  
  document.getElementById('statLatency').textContent = '‚Äî';
  
  log('Session stopped.', 'warn');
}

// --- Main Processing Loop ---
async function processFrame(timestamp) {
  if (!camStream || video.readyState < 2) {
    detectionLoopId = requestAnimationFrame(processFrame);
    return;
  }

  // Throttle (Poll Rate)
  if (timestamp - lastProcessTime < pollRate) {
    detectionLoopId = requestAnimationFrame(processFrame);
    return;
  }
  lastProcessTime = timestamp;

  const startTime = performance.now();
  
  // Clear previous drawings
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  let detections = [];

  if (activeMode === 'onnx') {
    // Only run if session exists, otherwise skip (safeguard against model load fail)
    if (ortSession) {
      try {
        detections = await runYoloInference();
      } catch (e) {
        console.warn("Inference Error:", e);
      }
    }
  } else {
    detections = runHSVInference();
  }

  const latency = Math.round(performance.now() - startTime);
  document.getElementById('statLatency').textContent = latency + 'ms';
  
  updateStats(detections);
  drawDetections(detections);
  
  detectionLoopId = requestAnimationFrame(processFrame);
}

// --- ALGORITHM 1: YOLOv8 ONNX ---
async function runYoloInference() {
  document.getElementById('glassBoxText').textContent = "Mode: ONNX (YOLOv8)\n1. Input: Resizing frame to 640x640\n2. Norm: converting RGB to float32 (0-1)\n3. Infer: Running CNN model\n4. Output: Decoding boxes & NMS";

  // 1. Prepare Input
  const modelInputShape = [1, 3, 640, 640];
  const matC = document.createElement('canvas');
  matC.width = 640; matC.height = 640;
  const matCtx = matC.getContext('2d');
  matCtx.drawImage(video, 0, 0, 640, 640);
  
  const imgData = matCtx.getImageData(0,0,640,640).data;
  const float32Data = new Float32Array(3 * 640 * 640);
  
  // HWC to CHW and Normalize
  for (let i = 0; i < 640 * 640; i++) {
    float32Data[i] = imgData[i * 4] / 255.0;              // R
    float32Data[i + 640*640] = imgData[i * 4 + 1] / 255.0; // G
    float32Data[i + 2*640*640] = imgData[i * 4 + 2] / 255.0; // B
  }

  const inputTensor = new ort.Tensor('float32', float32Data, modelInputShape);
  
  // 2. Run Inference
  const feeds = { images: inputTensor }; 
  const results = await ortSession.run(feeds);
  const output = results.output0.data; 
  
  // 3. Post Process
  // YOLOv8 Output shape is usually [1, 5, 8400] for 1 class (cx, cy, w, h, conf)
  const boxes = [];
  const numAnchors = 8400; 
  // Loop through anchors
  for (let i = 0; i < numAnchors; i++) {
    // Row 4 is confidence (if single class)
    const conf = output[4 * numAnchors + i]; 
    
    if (conf > threshold) {
      const cx = output[0 * numAnchors + i];
      const cy = output[1 * numAnchors + i];
      const w  = output[2 * numAnchors + i];
      const h  = output[3 * numAnchors + i];
      
      const x1 = cx - w/2;
      const y1 = cy - h/2;
      const x2 = cx + w/2;
      const y2 = cy + h/2;
      
      boxes.push({ 
        x1, y1, x2, y2, 
        conf, 
        label: 'fire' 
      });
    }
  }

  return nms(boxes);
}

function nms(boxes) {
  if (boxes.length === 0) return [];
  
  // Sort by confidence
  boxes.sort((a,b) => b.conf - a.conf);
  
  const selected = [];
  while (boxes.length > 0) {
    const best = boxes.shift();
    selected.push(best);
    
    boxes = boxes.filter(b => {
      const iou = calculateIoU(best, b);
      return iou < 0.45; // NMS Threshold
    });
  }
  
  // Scale boxes back to video size
  const scaleX = video.videoWidth / 640;
  const scaleY = video.videoHeight / 640;
  
  return selected.map(b => ({
    x: b.x1 * scaleX,
    y: b.y1 * scaleY,
    w: (b.x2 - b.x1) * scaleX,
    h: (b.y2 - b.y1) * scaleY,
    conf: b.conf,
    label: b.label
  }));
}

function calculateIoU(boxA, boxB) {
  const xA = Math.max(boxA.x1, boxB.x1);
  const yA = Math.max(boxA.y1, boxB.y1);
  const xB = Math.min(boxA.x2, boxB.x2);
  const yB = Math.min(boxA.y2, boxB.y2);
  const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
  const boxAArea = (boxA.x2 - boxA.x1) * (boxA.y2 - boxA.y1);
  const boxBArea = (boxB.x2 - boxB.x1) * (boxB.y2 - boxB.y1);
  return interArea / (boxAArea + boxBArea - interArea);
}

// --- ALGORITHM 2: HSV Rules ---
function runHSVInference() {
  document.getElementById('glassBoxText').textContent = "Mode: HSV (Rule-based)\n1. Scan: Iterating pixels\n2. Filter: Checking Hue < 25 (Orange/Red), Sat > 50%, Val > 60%\n3. Aggregate: Finding min/max bounds of matching pixels.";
  
  const w = canvas.width;
  const h = canvas.height;
  
  // Draw current frame to hidden context to read pixels
  ctx.drawImage(video, 0, 0, w, h);
  const frameData = ctx.getImageData(0, 0, w, h);
  const data = frameData.data;
  
  let minX = w, minY = h, maxX = 0, maxY = 0;
  let pixelCount = 0;
  
  // Stride for performance
  const stride = 4; 
  for (let y = 0; y < h; y += stride) {
    for (let x = 0; x < w; x += stride) {
      const i = (y * w + x) * 4;
      const r = data[i], g = data[i+1], b = data[i+2];
      
      // Simple pre-check: Red dominance
      if (r > 160 && r > g && g > b) {
        // Full HSV check
        const hsv = rgbToHsv(r, g, b); // [0-360, 0-1, 0-1]
        
        // Fire logic: 
        // Hue: 0-30 (Red/Orange) or 340-360 (Red)
        // Sat: > 0.5 (Vivid)
        // Val: > 0.6 (Bright)
        if ((hsv[0] < 30 || hsv[0] > 340) && hsv[1] > 0.5 && hsv[2] > 0.6) {
             if (x < minX) minX = x;
             if (x > maxX) maxX = x;
             if (y < minY) minY = y;
             if (y > maxY) maxY = y;
             pixelCount++;
        }
      }
    }
  }
  
  // Noise filter: Need a cluster of pixels to call it fire
  if (pixelCount > 60) {
    // Fake confidence based on density
    const area = (maxX - minX) * (maxY - minY);
    const density = pixelCount / (area / (stride*stride)); 
    const conf = Math.min(0.99, density + 0.3); // Heuristic

    if (conf >= threshold) {
      return [{
        x: minX, y: minY,
        w: maxX - minX, h: maxY - minY,
        conf: conf,
        label: 'HSV-Fire'
      }];
    }
  }
  return [];
}

function rgbToHsv(r, g, b) {
  r /= 255, g /= 255, b /= 255;
  const max = Math.max(r, g, b), min = Math.min(r, g, b);
  let h, s, v = max;
  const d = max - min;
  s = max === 0 ? 0 : d / max;
  if (max === min) {
    h = 0; 
  } else {
    switch (max) {
      case r: h = (g - b) / d + (g < b ? 6 : 0); break;
      case g: h = (b - r) / d + 2; break;
      case b: h = (r - g) / d + 4; break;
    }
    h /= 6;
  }
  return [h * 360, s, v];
}

// --- Draw & Stats ---
function updateStats(detections) {
  const valid = detections.filter(d => d.conf >= threshold);
  
  if (valid.length > 0) {
    document.getElementById('statFire').textContent = 'DETECTED';
    document.getElementById('statStatus').textContent = 'ALERT';
    document.getElementById('statCount').textContent = valid.length;
    
    const best = valid.reduce((p, c) => p.conf > c.conf ? p : c);
    document.getElementById('statConf').textContent = (best.conf * 100).toFixed(0) + '%';
  } else {
    document.getElementById('statFire').textContent = 'CLEAR';
    
    document.getElementById('statStatus').textContent = 'SCANNING';

    document.getElementById('statConf').textContent = '‚Äî';
    document.getElementById('statCount').textContent = 0;
  }
}

function drawDetections(list) {
  list.forEach(d => {
    if (d.conf < threshold) return;
    
    const x = d.x; 
    const y = d.y;
    const w = d.w;
    const h = d.h;
    
    const label = `${d.label} ${(d.conf*100).toFixed(0)}%`;

    // Draw Box
    ctx.strokeStyle = activeMode === 'onnx' ? '#ff4444' : '#f59e0b';
    ctx.lineWidth = 3;
    ctx.strokeRect(x, y, w, h);

    // Draw Label
    ctx.fillStyle = activeMode === 'onnx' ? '#ff4444' : '#f59e0b';
    const textW = ctx.measureText(label).width + 10;
    ctx.fillRect(x, y - 24, textW, 24);

    ctx.fillStyle = 'white';
    ctx.font = 'bold 14px Inter, sans-serif';
    ctx.fillText(label, x + 5, y - 7);
  });
}

// Auto Init
window.onload = () => {
    // Default to ONNX
    setMode('onnx');
};
</script>

</body>
</html>